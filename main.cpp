//opencv
#include "opencv2/imgcodecs.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
//C
#include <stdio.h>
//C++
#include <fstream>
#include <iostream>
#include <sstream>
using namespace cv;
using namespace std;

#define IM_W 640
#define IM_H 480
#define OFF_W 5
#define OFF_H 20

// Global variables
Mat frame; //current frame
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
Mat resultat;
Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
int keyboard; //input from keyboard


    //ranges, mis en global car ne changent jamais et utilisées par plusieurs fonctions
    const float huerange[] = {0, 180};
    const float satrange[] = {0, 256};
    const float *ranges[] = {huerange, satrange};




void help();
void processVideo();
using namespace cv;
cv::VideoCapture capture;

void help()
{
    cout
    << "--------------------------------------------------------------------------" << endl
    << "This program shows how to use background subtraction methods provided by "  << endl
    << " OpenCV. You can process both videos (-vid) and images (-img)."             << endl
                                                                                    << endl
    << "Usage:"                                                                     << endl
    << "./bs {-vid <video filename>|-img <image filename>}"                         << endl
    << "for example: ./bs -vid video.avi"                                           << endl
    << "or: ./bs -img /data/images/1.png"                                           << endl
    << "--------------------------------------------------------------------------" << endl
    << endl;
}
int main(int argc, char* argv[])
{
    //print help information
    help();

    capture=cv::VideoCapture(0);
    if(!capture.isOpened())
    {
        std::cerr<<"Failed to open Camera"<<std::endl;
        exit(1);
    }

    //create GUI windows
 
    //create Background Subtractor objects
    pMOG2 = createBackgroundSubtractorMOG2(5,2); //MOG2 approach
   
    processVideo();
   
    //destroy GUI windows
    destroyAllWindows();
}



void show_2d_hist(MatND &hist, char * name, int huebins = 30, int satbins = 32){
    double maxVal = 0;
    minMaxLoc(hist, 0, &maxVal, 0, 0); //on trouve la valeur max de l'histogramme

    int scale = 10;
    Mat histImg = Mat::zeros(satbins * scale, huebins * 10, CV_8UC3);

    for( int h = 0; h < huebins; h++ )
        for( int s = 0; s < satbins; s++ )
        {
            float binVal = hist.at<float>(h, s);
            int intensity = cvRound(binVal*255/maxVal);
            rectangle( histImg, Point(h*scale, s*scale),
                        Point( (h+1)*scale - 1, (s+1)*scale - 1),
                        Scalar::all(intensity),
                        CV_FILLED );
        }
    namedWindow(name, 1);
    imshow(name, histImg);
}


MatND hue_saturation_histogram(Mat &image, int huebins = 30, int satbins = 32)
{
    Mat image_hsv; //structure pour recevoir l'image convertie en hsv

    cvtColor(image, image_hsv, CV_BGR2HSV); //conversion de l'image en hsv

    int histSize[] = {huebins, satbins};

    const int channels[] = {0, 1};

    MatND hist;

    calcHist(   &image_hsv, 1, channels, Mat(), //pas de masque
                hist, 2, //2 dimensions
                histSize, ranges
                );

    return hist;
}



MatND normalized_hue_saturation_histogram(MatND &hist){
    MatND n_hist;
    normalize( hist, n_hist, 0, 255, NORM_MINMAX, -1, Mat() );
    return n_hist;
}

MatND hue_saturation_backprojection(Mat image, MatND hs_hist, int huebins = 30, int satbins = 32){ //mat: image RGB, hs_hist: histogramme H-S normalisé
    Mat image_hsv;
    cvtColor(image, image_hsv, CV_BGR2HSV);

    int channels[] = { 0, 1 };

    MatND backproj;
    calcBackProject(&image_hsv, 1, channels, hs_hist, backproj, ranges, 1, true);
    return backproj;
}

void draw_sub_window(int x, int y, Mat &parent, Mat child, char *text){

    child.copyTo(parent(cv::Rect( x * (OFF_W + IM_W) + OFF_W, y * (OFF_H + IM_H) + OFF_H, IM_W, IM_H)));
    putText(parent, text, Point(x * (OFF_W + IM_W) + OFF_W, y * (OFF_H + IM_H) + OFF_H - 5), FONT_HERSHEY_PLAIN, 1, Scalar(0, 0, 255));


}

void processVideo() {
    //create the capture object
    Mat global_im = Mat( 2 * (IM_H + OFF_H), 2 * (IM_W + OFF_W), CV_8UC3);
    Size glob_size = global_im.size();
    Mat sub_mat = Mat(IM_W, IM_H, CV_8UC3);
    int label_nb;
    Mat hand = cv::imread("main3.png");
    Mat im_hsv;
    vector<Mat> hsv_channels;
    Mat smoothed_frame;
    MatND hand_hs_hist = hue_saturation_histogram(hand);
    MatND backproj;
    Mat background;
    Mat thresd_backproj;
    Mat labels;
    Mat label_img = Mat(IM_H, IM_W, CV_8UC3);
    Mat connect_stats;
    Mat centroids;

    vector<Point> points_capture;
    vector<Mat> hand_subdivisions;
    
    Point taille_captures = Point(10, 10);
    //read input data. ESC or 'q' for quitting
    while( (char)keyboard != 'q' && (char)keyboard != 27 ){
        //read the current frame
        if(!capture.read(frame)) {
            cerr << "Unable to read next frame." << endl;
            cerr << "Exiting..." << endl;
            exit(EXIT_FAILURE);
        }
        label_img = frame;
     //   std::cout << "size :" << global_im.size().width << " " << global_im.size().height << std::endl;


        //get the frame number and write it on the current frame
       
        //show the current frame and the fg masks
        
        cvtColor(frame, im_hsv, CV_BGR2HSV);
        split(im_hsv, hsv_channels);
        equalizeHist(hsv_channels[2], hsv_channels[2]);
        merge(hsv_channels, im_hsv);
        cvtColor(im_hsv, frame, CV_HSV2BGR);
        GaussianBlur(frame, smoothed_frame, Size(15, 15), 0);

//update the background model
        pMOG2->apply(smoothed_frame, fgMaskMOG2, 0.0001);
        pMOG2->getBackgroundImage(background);
        cv::bitwise_and(smoothed_frame, smoothed_frame, resultat,  fgMaskMOG2);

        backproj = hue_saturation_backprojection(smoothed_frame, hand_hs_hist);


        threshold(backproj, thresd_backproj, 50, 255, THRESH_BINARY);
        label_nb = connectedComponentsWithStats(thresd_backproj, labels, connect_stats, centroids, 8, CV_32S);


        
        //get the input from the keyboard
        keyboard = waitKey( 30 );

        sub_mat = frame;
        Point p = Point(10, 10);
     
        int off_x = 30, off_y = 30, rect_w = 10, rect_h = 10;
        Point start_point = Point(50, 100);

        //rectangle(frame, Point(10, 10), Point(200, 300), Scalar(0, 0, 255));

        rectangle(frame, start_point + Point(off_x, -off_y), start_point + Point(off_x, -off_y) + Point(10, 10), Scalar(0, 0, 255));
        for(int i = 0; i < 3; i += 1){
            for(int j = 0; j < 3; j+= 1){
                Point p1 = start_point + Point(i * off_x, j * off_y);
                points_capture.push_back(p1);
                Point p2 = p1 + Point(rect_w, rect_h);
                rectangle(frame, p1, p2, Scalar(0, 0, 255));    
            }
            
        }
        draw_sub_window(0, 0, global_im, frame, "Frame");
        draw_sub_window(1, 0, global_im, smoothed_frame, "Image pretraitee");
        draw_sub_window(0, 1, global_im, background, "Estimation background");
        draw_sub_window(1, 1, global_im, resultat, "Resultat back sub");
        
        imshow("global", global_im);
        //imshow("FG Mask MOG 2", fgMaskMOG2);
       
        imshow("Backproj", backproj);
        imshow("Thr_backproj", thresd_backproj);
        //imshow("zones", labels);


        if((char)keyboard == 'a'){
            std::cout << "ecriture\n";
            cv::imwrite("test.png", frame);
        }else if((char)keyboard == 'b'){
            std::cout << labels;
        }else if((char)keyboard == 's'){
            for(auto p : points_capture){
                hand_subdivisions.push_back(Mat(frame, cv::Rect(p, p + taille_captures)));
            
            }
            int i = 0;
            /*for(auto m : hand_subdivisions){
                imshow(std::string("test") + std::to_string(i),m);
                i++;
            }*/
            imshow("test", hand_subdivisions[0]);
        }

        int biggest_label = 1, max_area = connect_stats.at<int>(1, CC_STAT_AREA);
        for(int label = 2; label < label_nb; label++){
            int area = connect_stats.at<int32_t>(label, CC_STAT_AREA);
            if(area > max_area){
                biggest_label = label;
                max_area = area;
            }
        }
       
       // std::cout << "max label: " << "max area :" << max_area << std::endl;

        for(int j = 0; j < IM_W; j++){
            for(int i = 0; i < IM_H; i++){
                //std::cout << i << " " << j << " " << labels.at<int>(i, j) << std::endl;
                int label = labels.at<int32_t>(i, j);
                int area = connect_stats.at<int32_t>(label, CC_STAT_AREA);
                //std::cout << i << " " << j << "a: " << area << "l: " << label;
                //std::cout << "stat: " << connect_stats.at<int>(label, CC_STAT_AREA) << " label: " << label << " x: " << j << " y " << i << " size: " << labels.size() <<std::endl;
                //if(label == biggest_label)label_img.at<Vec3b>(i, j) = {128, 0, 0};
                if(label == biggest_label)label_img.at<Vec3b>(i, j) = {128, 0, 0};
               // else label_img.at<uchar>(i, j) = (uchar)0;
            }
        }
        imshow("img", label_img);
      
        smoothed_frame.release();
        resultat.release();
        backproj.release();
        thresd_backproj.release();






    }
    std::ofstream f;
        f.open("test.txt");
        f << labels << std::endl;
        f.close();
    //delete capture object
    capture.release();
}
